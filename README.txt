xxj_retry_demo.py    # 自定义重试模块

thread_retry(xxj_retry_demo).py    # 单线程重试（无ip限制）    使用xxj自定义重试模块实现重试机制

thread_retry(retrying).py  # 单线程重试（无ip限制）    使用python第三方重试模块retrying实现重试机制

thread_retry_proxy(xxj_retry_demo).py    # 单线程重试（ip限制）    使用xxj自定义重试模块实现重试机制

************************************     # 单线程重试（ip限制）    使用python第三方重试模块retrying实现重试机制  (该模块无法实现切换代理后再重试机制)

# 对于单线程而言：推荐使用xxj_retry_demo    （对于可以放入队列中实现的， 可以采用丢回队列的重试方法实现重试机制）

# 对于多线程而言用到很多的方法就是丢回到队列中，从而实现重试的机制。    （****但是另一种重试机制： 针对于多线程代理ip失效后，实现获取新代理然后再重试的这种重试机制也很重要****）




情景一：针对单线程爬虫的异常重试机制（无ip被封现象）
        爬虫过程中所出现的异常分为两种类型（1、请求相关异常：如超时异常等；2、网站页面变化后解析失败的异常）[对于异常1可以采取重试机制；对于异常2而言就应该报错体现出来并调整代码]   所以说，爬虫项目的重试主要是针对请求相关的重试
        方案：因为仅仅主要对请求异常进行重试。所以只要对请求进行重试封装即可。（1、可以通过xxj自定义的重试模块实现；2、可以通过retrying重试模块实现重试机制）


情景二：针对单线程爬虫的异常重试机制（有ip被封现象）
	重试思想依旧是针对请求进行重试，在请求的过程中（1、非ip被封的异常：如超时；2、ip被封的异常：如ConnectionError；3、IP被封时的响应状态码；4、返回内容体现了ip被封。）【简而言之：就是一种是非ip被封时的异常现象；另一种就是ip被封的异常现象】
	所以对于非ip被封的异常现象只需要进行重试操作；对于ip被封现象时应该实现切换代理ip然后再重试。
	方案：1、可以通过xxj自定义的重试模块实现; 2、对于如果使用retrying模块而言，因为它的重试是对当前函数进行再一次重试（所以无法实现切换代理ip后进行重试）   【推荐使用方法一】

上面的方法具有通用型；
另一种重试的思想：
	简单的爬虫项目：如果对于可以归类为一份来源数据的爬虫项目。那么就可以不需要重试模块。因为可以捕获到异常，然后将异常的来源数据重新丢回到源数据队列中（这样的话，不管是否是由于ip被限制的异常的源数据都丢回到源数据队列中。然后针对是ip限制的异常进行代理ip切换操作即可）
	复杂的爬虫项目：需要这种重试思想和上面的重试思想结合使用。



针对多线程爬虫的异常重试机制（无ip被封现象）
	其实对于多线程而言，我们就会先准备一个源数据队列（可以是数据方提供过来的源数据；也可以根据一些起始的页面（种子页面）获取到相关数据作为源数据），这样就可以很好地用到多线程（因为Queue是线程安全的）
		对于简单的爬虫项目：如源数据队列中的每一个数据都可以对应到一个链接url对应到一条需求抓取数据。那么捕获相应异常实现将异常数据丢回到源数据队列中进行重新抓取（这样可以实现无丢失的爬虫抓取）。
		对于复杂的爬虫类型：如一个源数据需要构造出一条链接url，然后又延伸到一条链接url（深度遍历）（如果对于中间的某条数据的异常丢失造成其他数据都无法抓取的类型），【# 需要分类处理，对于和源数据关联比较大链接url的异常，可以实现将异常数据丢回到源数据队列中；对于很重要的中间链接url可以通过retrying重试模块实现重试（不能使用xxj的重试模块，不适用于多线程？？？）】

针对多线程爬虫的异常重试机制（具有ip被封现象）
	其实对于多线程而言，我们就会先准备一个源数据队列（可以是数据方提供过来的源数据；也可以根据一些起始的页面（种子页面）获取到相关数据作为源数据），这样就可以很好地用到多线程（因为Queue是线程安全的）
		对于简单的爬虫项目：如源数据队列中的每一个数据都可以对应到一个链接url对应到一条需求抓取数据。那么捕获相应异常实现将异常数据丢回到源数据队列中进行重新抓取（这样可以实现无丢失的爬虫抓取）。（仅仅只需要对相应的线程对应得代理限制的ip进行切换就ok了）
		对于复杂的爬虫类型：如一个源数据需要构造出一条链接url，然后又延伸到一条链接url（深度遍历）（如果对于中间的某条数据的异常丢失造成其他数据都无法抓取的类型），【# 需要分类处理，对于和源数据关联比较大链接url的异常，可以实现将异常数据丢回到源数据队列中；对于很重要的中间链接url可以通过retrying重试模块实现重试（不能使用xxj的重试模块，不适用于多线程？？？）】


总结：
	对于单线程的两种情况：不管爬虫项目是否复杂，都是可以通过xxj自定义的重试模块进行优化（最多就是重试次数设置大一点）
	对于多线程的两种情况：对于无ip限制的项目，就是丢回到队列和retrying重试模块结合使用（最多就是retrying重试模块的重试次数设置大一点）；但是对于ip限制的项目而言，实现丢回到队列是可以实现的，但是如何实现切换代理ip并且再次重试？？？

